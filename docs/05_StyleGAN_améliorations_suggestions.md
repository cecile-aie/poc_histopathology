# Analyse et Suggestions d'Am√©lioration - Notebook 05_StyleGAN.ipynb

## üìä √âtat Actuel

### Architecture Actuelle
- **Generator** : Version simplifi√©e StyleGAN2 (POC) sans plusieurs composants critiques
- **Discriminator** : Architecture simple avec spectral norm
- **Entra√Ænement** : 2 √©poques seulement, batch size 4
- **Dataset** : 2700 images (300 par classe √ó 9 classes)

---

## üî¥ Probl√®mes Critiques Identifi√©s

### 1. **Architecture du Generator - Manque de Composants Essentiels**

#### ‚ùå Probl√®mes :
- **Pas de blur kernel (upfirdn2d)** : Le commentaire dit "StyleGAN fait un upsample + blur; ici: up simple pour POC"
  - Impact : Artifacts d'aliasing, images floues, perte de d√©tails fins
- **Pas d'injection de bruit** : Aucun bruit ajout√© dans les blocs du g√©n√©rateur
  - Impact : Manque de variation stochastique, textures r√©p√©titives
- **Pas de style mixing** : Le m√™me w est utilis√© pour tous les blocs
  - Impact : Moins de contr√¥le sur les styles, g√©n√©ration moins vari√©e
- **Architecture trop simple** : Pas de skip connections, pas de modulation fine

#### ‚úÖ Solutions Recommand√©es :

**A. Impl√©menter le blur kernel (upfirdn2d)**
```python
# N√©cessite une impl√©mentation de upfirdn2d pour l'upsampling avec blur
# Utiliser une impl√©mentation existante (ex: stylegan2-pytorch) ou impl√©menter
# Le blur kernel r√©duit les artifacts d'aliasing lors de l'upsampling
```

**B. Ajouter l'injection de bruit**
```python
# Dans chaque bloc du g√©n√©rateur, ajouter :
# noise = torch.randn(batch_size, 1, h, w, device=x.device)
# x = x + noise * noise_weight  # o√π noise_weight est appris
```

**C. Impl√©menter le style mixing**
```python
# Utiliser diff√©rents w pour diff√©rents blocs :
# - w1 pour les blocs basse r√©solution (structure globale)
# - w2 pour les blocs haute r√©solution (d√©tails)
# Probabilit√© de style mixing : ~0.9 pendant l'entra√Ænement
```

---

### 2. **Architecture du Discriminator - Trop Simple**

#### ‚ùå Probl√®mes :
- Architecture tr√®s basique : juste des convs empil√©es
- Pas de features multiples pour la r√©gularisation
- Pas de r√©solution progressive
- Pas de feature matching loss

#### ‚úÖ Solutions Recommand√©es :

**A. Ajouter Feature Matching Loss**
```python
# Extraire les features interm√©diaires du D pour les vraies et fausses images
# Loss = ||D_features(real) - D_features(fake)||¬≤
# Cela guide le G √† produire des features similaires aux vraies images
```

**B. Am√©liorer l'architecture du D**
- Ajouter des r√©sidus (ResBlocks)
- Utiliser des features √† plusieurs r√©solutions
- Ajouter de la normalisation adaptative

---

### 3. **Hyperparam√®tres d'Entra√Ænement - Insuffisants**

#### ‚ùå Probl√®mes :
- **EPOCHS = 2** : Beaucoup trop peu ! StyleGAN n√©cessite des centaines d'√©poques
- **BATCH_SIZE = 4** : Tr√®s petit, limite la stabilit√©
- **SAMPLES_PER_CLASS = 300** : Peut √™tre insuffisant pour capturer la diversit√©
- **Pas de learning rate scheduling** : LR fixe peut limiter la convergence

#### ‚úÖ Solutions Recommand√©es :

**A. Augmenter drastiquement le nombre d'√©poques**
```python
EPOCHS = 50-100  # Minimum pour voir des r√©sultats d√©cents
# StyleGAN2 classique n√©cessite souvent 100-200+ √©poques
```

**B. Augmenter le batch size si possible**
```python
BATCH_SIZE = 8-16  # Si VRAM le permet
# Plus grand batch = gradients plus stables
```

**C. Ajouter un scheduler de learning rate**
```python
# Cosine annealing ou step decay
scheduler_G = torch.optim.lr_scheduler.CosineAnnealingLR(opt_G, T_max=EPOCHS)
scheduler_D = torch.optim.lr_scheduler.CosineAnnealingLR(opt_D, T_max=EPOCHS)
```

**D. Augmenter le dataset si possible**
```python
SAMPLES_PER_CLASS = 500-1000  # Plus de diversit√©
# Ou utiliser tout le dataset sans limitation
```

---

### 4. **Loss Functions - Manque de Guidance**

#### ‚ùå Probl√®mes :
- Pas de **perceptual loss** avec PathoDuet
- Pas de **feature matching loss**
- PathoDuet alpha trop faible (max 0.08)
- Pas de **path length regularization**

#### ‚úÖ Solutions Recommand√©es :

**A. Ajouter Perceptual Loss avec PathoDuet**
```python
# Utiliser PathoDuet pour guider le g√©n√©rateur
def perceptual_loss(fake, real):
    fake_feat = pathoduet(fake)
    real_feat = pathoduet(real)
    return F.mse_loss(fake_feat, real_feat)

# Ajouter √† la loss du g√©n√©rateur :
g_loss = g_nonsat_loss(fake_pred) + lambda_perceptual * perceptual_loss(fake, real)
```

**B. Augmenter le poids de PathoDuet**
```python
ALPHA_MAX = 0.2-0.5  # Au lieu de 0.08
# PathoDuet est sp√©cialis√© histopathologie, il devrait avoir plus de poids
```

**C. Ajouter Path Length Regularization**
```python
# R√©gularise la courbure de l'espace latent
# Aide √† avoir un espace latent plus lisse et contr√¥lable
```

**D. Feature Matching Loss**
```python
# Extraire features interm√©diaires du D
# Loss = ||D_intermediate(real) - D_intermediate(fake)||¬≤
```

---

### 5. **Augmentations ADA - Trop Limit√©es**

#### ‚ùå Probl√®mes :
- Augmentations tr√®s simples (flip, translation)
- Pas de rotation (importante pour histopathologie)
- Pas de color jitter (d√©sactiv√©)
- Pas de cutout/erasing

#### ‚úÖ Solutions Recommand√©es :

**A. Ajouter plus d'augmentations**
```python
def ada_augment_enhanced(x, p, translate=0.04, rotate=0.1, color=0.1, cutout=0.1):
    # Rotation (importante pour histopathologie)
    if torch.rand(1) < p:
        angle = (torch.rand(1) - 0.5) * 2 * rotate * 180
        x = F.affine(x, angle=angle, translate=[0,0], scale=1.0, shear=0)
    
    # Color jitter (variations de teinte H&E)
    if torch.rand(1) < p and color > 0:
        # Jitter sp√©cifique aux couleurs H&E
        ...
    
    # Cutout (simule les artefacts)
    if torch.rand(1) < p and cutout > 0:
        ...
```

**B. Augmenter ADA_MAX_P**
```python
ADA_MAX_P = 0.2-0.4  # Au lieu de 0.08
# Plus d'augmentations = meilleure g√©n√©ralisation
```

---

### 6. **Initialisation et Normalisation**

#### ‚ùå Probl√®mes :
- Pas d'initialisation sp√©cifique mentionn√©e
- Pas de normalisation adaptative dans le g√©n√©rateur

#### ‚úÖ Solutions Recommand√©es :

**A. Initialisation correcte des poids**
```python
# Initialiser les poids selon la distribution de StyleGAN2
# Utiliser une variance adapt√©e pour les ModulatedConv
```

**B. Ajouter Layer Normalization**
```python
# Dans les blocs du g√©n√©rateur, ajouter LayerNorm
# Aide √† la stabilit√© de l'entra√Ænement
```

---

### 7. **Progressive Growing (Optionnel mais Recommand√©)**

#### ‚úÖ Solution Recommand√©e :

**Impl√©menter Progressive Growing**
```python
# Commencer √† 4x4, puis augmenter progressivement : 8x8, 16x16, 32x32, 64x64, 128x128, 256x256
# Cela permet un apprentissage plus stable et des images de meilleure qualit√©
# Transition douce entre r√©solutions
```

---

### 8. **Utilisation de PathoDuet - Pas Optimale**

#### ‚ùå Probl√®mes :
- PathoDuet est gel√© (`torch.no_grad()`)
- Alpha trop faible (max 0.08)
- Pas utilis√© pour guider directement le g√©n√©rateur

#### ‚úÖ Solutions Recommand√©es :

**A. Utiliser PathoDuet comme Perceptual Loss**
```python
# Au lieu de juste dans le discriminateur, utiliser PathoDuet pour guider G
# Cela force G √† produire des images avec des features histopathologiques correctes
```

**B. Augmenter significativement alpha**
```python
ALPHA_MAX = 0.3-0.5  # PathoDuet est sp√©cialis√©, il devrait avoir plus de poids
```

**C. Utiliser PathoDuet d√®s le d√©but**
```python
ALPHA_FREEZE_UNTIL = 0  # Commencer avec PathoDuet activ√©
# Ou au moins beaucoup plus t√¥t (500 steps au lieu de 1500)
```

---

## üéØ Plan d'Action Prioritaire

### Priorit√© 1 (Critique - Impact Imm√©diat) :
1. ‚úÖ **Augmenter EPOCHS √† 50-100 minimum**
2. ‚úÖ **Ajouter l'injection de bruit dans le g√©n√©rateur**
3. ‚úÖ **Ajouter Perceptual Loss avec PathoDuet**
4. ‚úÖ **Augmenter ALPHA_MAX √† 0.3-0.5**
5. ‚úÖ **Augmenter BATCH_SIZE si VRAM le permet (8-16)**

### Priorit√© 2 (Important - Am√©lioration Significative) :
6. ‚úÖ **Impl√©menter le blur kernel (upfirdn2d)**
7. ‚úÖ **Ajouter Feature Matching Loss**
8. ‚úÖ **Am√©liorer les augmentations ADA (rotation, color jitter)**
9. ‚úÖ **Ajouter Learning Rate Scheduling**
10. ‚úÖ **Impl√©menter le style mixing**

### Priorit√© 3 (Am√©lioration Continue) :
11. ‚úÖ **Progressive Growing**
12. ‚úÖ **Path Length Regularization**
13. ‚úÖ **Am√©liorer l'architecture du Discriminator**
14. ‚úÖ **Augmenter SAMPLES_PER_CLASS**

---

## üìù D√©tails Techniques par Composant

### Generator - Modifications N√©cessaires

```python
class Generator(nn.Module):
    def __init__(self, z_dim=512, w_dim=512, img_res=256, fmap_base=256):
        # ... existant ...
        
        # AJOUTER : Noise injection pour chaque bloc
        self.noise_weights = nn.ParameterList([
            nn.Parameter(torch.zeros(1)) for _ in range(len(self.blocks))
        ])
        
    def forward(self, z, style_mixing_prob=0.9):
        w = self.mapping(z)
        
        # AJOUTER : Style mixing
        if self.training and torch.rand(1) < style_mixing_prob:
            w2 = self.mapping(torch.randn_like(z))
            cutoff = torch.randint(1, len(self.blocks), (1,))
            w = torch.cat([w[:cutoff], w2[cutoff:]])
        
        x = self.const.repeat(z.size(0), 1, 1, 1)
        
        for i, (m1, a1, m2, a2) in enumerate(self.blocks):
            # AJOUTER : Noise injection
            noise = torch.randn(x.size(0), 1, x.size(2), x.size(3), 
                               device=x.device) * self.noise_weights[i]
            x = x + noise
            
            x = m1(x, w); x = a1(x)
            x = m2(x, w); x = a2(x)
        
        img = torch.tanh(self.to_rgb(x))
        return img
```

### Loss Functions - Ajouts

```python
# Perceptual Loss avec PathoDuet
def perceptual_loss_pathoduet(fake, real, pathoduet_model):
    with torch.no_grad():
        real_feat = pathoduet_model(real)
    fake_feat = pathoduet_model(fake)
    return F.mse_loss(fake_feat, real_feat)

# Feature Matching Loss
def feature_matching_loss(real_pred, fake_pred, D_model):
    # Extraire features interm√©diaires (n√©cessite modification du D)
    real_feat = D_model.get_intermediate_features(real)
    fake_feat = D_model.get_intermediate_features(fake)
    return F.mse_loss(fake_feat, real_feat)

# Dans la boucle d'entra√Ænement :
g_loss = (g_nonsat_loss(fake_pred) + 
          LAMBDA_STATS * real_stats.penalty(fake) +
          LAMBDA_PERCEPTUAL * perceptual_loss_pathoduet(fake, real, pathoduet) +
          LAMBDA_FM * feature_matching_loss(real_pred, fake_pred, D))
```

### Augmentations ADA - Am√©liorations

```python
def ada_augment_histo(x, p, translate=0.04, rotate=0.05, color=0.1):
    """Augmentations adapt√©es √† l'histopathologie."""
    if p <= 0:
        return x
    
    b, c, h, w = x.shape
    
    # Rotation (crucial pour histopathologie)
    if torch.rand(1, device=x.device).item() < p and rotate > 0:
        angle = (torch.rand(1, device=x.device) - 0.5) * 2 * rotate * 180
        # Rotation avec interpolation bilin√©aire
        x = F.affine(x, angle=angle.item(), translate=[0,0], 
                    scale=1.0, shear=0, interpolation='bilinear')
    
    # Color jitter sp√©cifique H&E
    if torch.rand(1, device=x.device).item() < p and color > 0:
        # Jitter sur les canaux H (hematoxylin) et E (eosin)
        # Plus subtil que le jitter standard
        ...
    
    # Translation (existant mais am√©liorer)
    if translate > 0 and torch.rand(1, device=x.device).item() < p:
        max_pix = max(1, int(h * translate))
        dx = torch.randint(-max_pix, max_pix + 1, (1,), device=x.device).item()
        dy = torch.randint(-max_pix, max_pix + 1, (1,), device=x.device).item()
        x = torch.roll(x, shifts=(dx, dy), dims=(2, 3))
    
    return x
```

---

## üî¨ M√©triques √† Surveiller

### M√©triques Existantes (Bonnes) :
- ‚úÖ Duet-FID (excellent pour histopathologie)
- ‚úÖ Accuracy du discriminateur
- ‚úÖ Gap moyen entre real/fake

### M√©triques √† Ajouter :
- üìä **IS (Inception Score)** : Diversit√© des images g√©n√©r√©es
- üìä **LPIPS** : Distance perceptuelle entre images
- üìä **Fr√©quence des styles** : V√©rifier la diversit√© des styles g√©n√©r√©s
- üìä **Histogramme des couleurs** : Comparer avec les vraies images H&E
- üìä **M√©triques morphologiques** : Utiliser le SSM du notebook 04 pour comparer les formes

---

## üéì R√©f√©rences et Impl√©mentations

### Impl√©mentations StyleGAN2 Compl√®tes :
- **stylegan2-pytorch** : https://github.com/lucidrains/stylegan2-pytorch
- **stylegan2-ada-pytorch** : https://github.com/NVlabs/stylegan2-ada-pytorch (officiel NVIDIA)

### Papers Cl√©s :
- StyleGAN2 (Karras et al., 2020)
- StyleGAN2-ADA (Karras et al., 2020) - Adaptive Discriminator Augmentation
- Training Generative Adversarial Networks with Limited Data (Karras et al., 2020)

---

## ‚ö†Ô∏è Avertissements

1. **Temps d'entra√Ænement** : Avec 50-100 √©poques, l'entra√Ænement prendra beaucoup plus de temps
2. **VRAM** : Les am√©liorations peuvent n√©cessiter plus de m√©moire GPU
3. **Hyperparam√®tres** : Chaque modification n√©cessite un r√©glage fin des hyperparam√®tres
4. **Ordre d'impl√©mentation** : Impl√©menter les changements progressivement et tester √† chaque √©tape

---

## üìà R√©sultats Attendus

Avec ces am√©liorations, on devrait observer :
- ‚úÖ Images plus nettes et d√©taill√©es
- ‚úÖ Meilleure coh√©rence des textures histopathologiques
- ‚úÖ Diversit√© accrue dans les images g√©n√©r√©es
- ‚úÖ Duet-FID en baisse (meilleure qualit√©)
- ‚úÖ Meilleure s√©paration des classes (si conditionn√©)

---

## üöÄ Quick Wins (Am√©liorations Rapides)

Si vous voulez des r√©sultats rapides sans refonte compl√®te :

1. **Augmenter EPOCHS √† 20-30** (5 minutes de modification)
2. **Augmenter ALPHA_MAX √† 0.3** (1 minute)
3. **Ajouter Perceptual Loss avec PathoDuet** (15 minutes)
4. **Augmenter BATCH_SIZE √† 8** (si VRAM OK, 2 minutes)
5. **Ajouter rotation dans ADA** (10 minutes)

Ces 5 changements devraient d√©j√† am√©liorer significativement les r√©sultats.

