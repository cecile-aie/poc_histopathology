
-----

# üß¨ PixCell Gated: Pipeline d'Inf√©rence Conditionnelle

Ce dossier contient l'impl√©mentation de l'approche **"Gated"** (ou *Zero-Shot*) pour la g√©n√©ration d'images histopathologiques. Cette m√©thode utilise le mod√®le de diffusion **PixCell** pr√©-entra√Æn√©, conditionn√© directement par les embeddings s√©mantiques extraits par le Foundation Model **UNI2-h**.

Aucun entra√Ænement n'est r√©alis√© ici : il s'agit d'√©valuer la capacit√© du mod√®le pr√©-entra√Æn√© √† g√©n√©raliser sur notre domaine (NCT-CRC-HE) via un conditionnement par l'image (*Image-to-Image / Re-sampling*).

## ‚öôÔ∏è Architecture du Pipeline

Le flux de donn√©es repose sur l'interaction entre deux mod√®les fig√©s (*frozen*) :

1.  **Encodeur (UNI2-h)** : Extrait un vecteur de caract√©ristiques ($1 \times 1536$) √† partir d'une image r√©elle de r√©f√©rence.
2.  **G√©n√©rateur (PixCell)** : Mod√®le de diffusion latent qui utilise ce vecteur comme conditionnement pour g√©n√©rer une nouvelle variation de l'image.

<!-- end list -->

```mermaid
graph LR
    A[Image R√©elle] -->|Transform + Resize| B(UNI2-h Encoder)
    B -->|Embedding 1536d| C{Conditioning}
    C -->|Injection Cross-Attention| D[PixCell Diffusion]
    D -->|Denoising| E[Image Synth√©tique]
```

## üõ†Ô∏è Impl√©mentation Technique & "Monkey-Patching"

L'utilisation de PixCell avec la librairie standard `diffusers` n√©cessite une adaptation sp√©cifique du code, car le mod√®le attend nativement des prompts textuels ou un format de conditionnement diff√©rent.

### 1\. Le "Monkey-Patch"

Pour injecter les embeddings visuels d'UNI2-h (dimension 1536) directement dans le Transformer de PixCell, nous appliquons un **monkey-patch** sur la classe `PixArtTransformer2DModel`.

  * **Probl√®me :** Le pipeline standard s'attend √† un embedding textuel (T5/CLIP) de dimension 4096 ou 1152.
  * **Solution :** Nous surchargeons la m√©thode `forward` ou le module d'embedding pour accepter nos tenseurs `[Batch, 1, 1536]`. Cela permet de "court-circuiter" l'encodeur de texte et de forcer l'utilisation de l'embedding histologique.

### 2\. Gestion du Foundation Model (UNI2-h)

Le mod√®le UNI2-h est charg√© via `timm` en mode √©valuation.

  * **Astuce d'int√©gration :** Les poids doivent √™tre charg√©s manuellement depuis le checkpoint `.bin`.
  * **Attention aux dimensions :** UNI2-h attend strictement des images en **224x224**. Une √©tape de redimensionnement est critique avant l'encodage, ind√©pendamment de la taille de g√©n√©ration de PixCell (256x256).

### 3\. Normalisation Vahadane

Pour garantir que le conditionnement capture la structure tissulaire et non les biais de coloration, les images de r√©f√©rence passent par une **normalisation Vahadane** avant d'√™tre envoy√©es √† UNI2-h.

## üöÄ Utilisation

Le script principal charge le pipeline et g√©n√®re des images bas√©es sur des √©chantillons du dataset de validation.

```python
# Pseudo-code d'utilisation
from models import load_uni2h, load_pixcell_gated

# 1. Chargement des mod√®les (Frozen)
uni_model = load_uni2h(device="cuda")
pipeline = load_pixcell_gated(model_path="...", device="cuda")

# 2. Monkey-Patching (Automatique au chargement)
# Le pipeline est modifi√© pour accepter 'encoder_hidden_states' custom

# 3. Extraction de l'embedding
real_img = load_image("tumeur.png") # + Normalisation Vahadane
emb = uni_model(preprocess(real_img)) # [1, 1536]

# 4. G√©n√©ration
image = pipeline(
    num_inference_steps=20,
    encoder_hidden_states=emb.unsqueeze(1),
    guidance_scale=4.5
).images[0]
```

## ‚ö†Ô∏è Limitations observ√©es

Bien que fonctionnelle, cette approche "na√Øve" pr√©sente un **Domain Shift** :

  * Le mod√®le PixCell de base a √©t√© entra√Æn√© sur un large corpus (TCGA, etc.) qui diff√®re de la colorim√©trie sp√©cifique du dataset NCT-CRC-HE.
  * Sans fine-tuning (LoRA/Adapter), les images g√©n√©r√©es peuvent pr√©senter des incoh√©rences de texture ou de teinte par rapport √† la cible.

C'est pour pallier ce d√©faut que l'approche **Trainable (Adapter + LoRA)** a √©t√© d√©velopp√©e (voir section correspondante).