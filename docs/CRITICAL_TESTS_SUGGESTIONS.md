# ğŸ” Tests Critiques Manquants - Notebook 01_test_datagenerator.ipynb

## âœ… Ce qui a Ã©tÃ© testÃ© (bien couvert)
- Configuration JSON des seuils
- Chargement train/val avec Ã©chantillonnage
- Normalisation Vahadane (activation)
- Calibration des mÃ©triques qualitÃ©
- Visualisation et DataLoader
- Mapping des classes
- SÃ©paration train/val
- Filtrage qualitÃ© (taux de passage)
- Modes CNN et GAN (pixel_range, return_labels)
- Filtrage par classes spÃ©cifiques

## âš ï¸ Aspects CRITIQUES non testÃ©s

### 1. ğŸ”„ **Test de `no_repeat_eval=True` en mode validation** âš ï¸ CRITIQUE
**ProblÃ¨me potentiel** : La cellule 3 charge `ds_val` avec `no_repeat_eval=True`, mais il n'y a **aucun test** pour vÃ©rifier que :
- Les images ne se rÃ©pÃ¨tent pas entre les Ã©poques en mode validation
- Le comportement est diffÃ©rent entre train (avec remise) et val (sans remise)

**Test suggÃ©rÃ©** :
```python
# Test no_repeat_eval en validation
ds_val_test = HistoDataset(
    root_data=ROOT_DATA,
    split="val",
    output_size=IMG_SIZE,
    thresholds_json_path="seuils_par_classe.json",
    vahadane_enable=False,
    samples_per_class_per_epoch=50,
    no_repeat_eval=True  # â† Important
)

# VÃ©rifier que les images ne se rÃ©pÃ¨tent pas entre Ã©poques
epoch_0_paths = {os.path.basename(p) for _, _, p in [ds_val_test[i] for i in range(len(ds_val_test))]}
ds_val_test.set_epoch(1)
epoch_1_paths = {os.path.basename(p) for _, _, p in [ds_val_test[i] for i in range(len(ds_val_test))]}

overlap = len(epoch_0_paths & epoch_1_paths)
print(f"Chevauchement entre Ã©poques: {overlap} (devrait Ãªtre 0 si no_repeat_eval=True)")
assert overlap == 0, "âŒ Les images se rÃ©pÃ¨tent entre Ã©poques en validation !"
```

### 2. ğŸ” **Test de cohÃ©rence des indices `_epoch_indices`** âš ï¸ IMPORTANT
**ProblÃ¨me potentiel** : VÃ©rifier que les indices dans `_epoch_indices` correspondent bien aux images chargÃ©es et que `subsample_dataset` fonctionne correctement.

**Test suggÃ©rÃ©** :
```python
# VÃ©rifier que subsample_dataset prÃ©serve la cohÃ©rence
for idx in ds_train_small.indices[:10]:
    ci, j = ds_train[0]._epoch_indices[idx]  # Index dans le dataset complet
    path_expected = ds_train.paths_by_class[ci][j]
    _, _, path_actual = ds_train_small[0]  # Premier Ã©lÃ©ment du subset
    # VÃ©rifier que les chemins correspondent
```

### 3. ğŸš¨ **Test des cas limites du filtrage qualitÃ©** âš ï¸ CRITIQUE
**ProblÃ¨me observÃ©** : La cellule 20 montre que certaines classes ont un taux de rejet trÃ¨s Ã©levÃ© :
- MUC: 11/50 OK (78% rejetÃ©)
- DEB: 20/50 OK (60% rejetÃ©)
- NORM: 20/50 OK (60% rejetÃ©)

**Risque** : Si trop d'images sont rejetÃ©es, le dataset peut devenir trop petit ou dÃ©sÃ©quilibrÃ©.

**Test suggÃ©rÃ©** :
```python
# Test du comportement quand le filtre rejette trop d'images
# VÃ©rifier que le mÃ©canisme de retry (max 5 tentatives) fonctionne
# VÃ©rifier qu'on n'obtient pas d'erreur si toutes les images d'une classe sont rejetÃ©es

for ci, cname in ds_train.idx_to_class.items():
    paths = ds_train.paths_by_class[ci]
    rejected_count = 0
    for path in paths[:100]:  # Ã‰chantillon
        img = Image.open(path)
        metrics = ds_train.qf.score(img)
        thr = ds_train.class_thresholds.get(cname, {})
        if not ds_train.qf.check(metrics, thr):
            rejected_count += 1
    
    rejection_rate = rejected_count / min(100, len(paths))
    print(f"{cname}: {rejection_rate:.1%} rejetÃ©")
    if rejection_rate > 0.9:
        print(f"âš ï¸ ATTENTION: {cname} a un taux de rejet > 90% !")
```

### 4. ğŸ”„ **Test de la stabilitÃ© de la normalisation Vahadane** âš ï¸ IMPORTANT
**ProblÃ¨me potentiel** : VÃ©rifier que la normalisation Vahadane est cohÃ©rente entre les Ã©poques et ne cause pas de dÃ©rive.

**Test suggÃ©rÃ©** :
```python
# Test de cohÃ©rence de la normalisation
sample_path = random.choice(ds_train.paths_by_class[0])
img_raw = Image.open(sample_path)

# Normaliser plusieurs fois
img_norm_1 = ds_train.stain.normalize(img_raw)
ds_train.set_epoch(1)  # RÃ©initialiser
img_norm_2 = ds_train.stain.normalize(img_raw)

# VÃ©rifier que les rÃ©sultats sont identiques (ou trÃ¨s proches)
diff = np.abs(np.array(img_norm_1) - np.array(img_norm_2)).mean()
print(f"DiffÃ©rence moyenne entre normalisations: {diff:.6f}")
assert diff < 1.0, "âŒ La normalisation n'est pas stable !"
```

### 5. ğŸ“Š **Test de l'Ã©quilibrage rÃ©el dans les batches** âš ï¸ IMPORTANT
**Observation** : La cellule 16 montre une rÃ©partition inÃ©gale (ADI: 13.8%, MUC: 8.8%), ce qui est normal avec shuffle, mais il faudrait vÃ©rifier sur plusieurs Ã©poques.

**Test suggÃ©rÃ©** :
```python
# Test de l'Ã©quilibrage sur plusieurs Ã©poques
from collections import Counter

all_counts = Counter()
for epoch in range(5):
    ds_train.set_epoch(epoch)
    loader = DataLoader(ds_train_small, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)
    for i, (_, y, _) in enumerate(loader):
        if i >= 20:  # 20 batches par Ã©poque
            break
        all_counts.update(y.cpu().numpy())

# VÃ©rifier que la distribution est Ã©quilibrÃ©e sur plusieurs Ã©poques
total = sum(all_counts.values())
for ci, count in sorted(all_counts.items()):
    class_name = ds_train.idx_to_class[ci]
    proportion = count / total * 100
    expected = 100 / len(ds_train.paths_by_class)  # ~11.1% pour 9 classes
    print(f"{class_name}: {proportion:.1f}% (attendu: ~{expected:.1f}%)")
```

### 6. ğŸ›¡ï¸ **Test de robustesse (fichiers corrompus, chemins invalides)** âš ï¸ BONUS
**Test suggÃ©rÃ©** :
```python
# VÃ©rifier que le dataset gÃ¨re gracieusement les erreurs
# (dÃ©jÃ  partiellement testÃ© dans __getitem__ avec le retry, mais pourrait Ãªtre plus complet)
```

### 7. ğŸ”¢ **Test des ranges de pixels (0_1, -1_1, imagenet)** âš ï¸ IMPORTANT
**Observation** : La cellule 26 teste les modes CNN et GAN, mais pas le mode "imagenet".

**Test suggÃ©rÃ©** :
```python
# Test du mode imagenet
ds_imagenet = HistoDataset(
    root_data=str(DATA_ROOT),
    split="train",
    output_size=IMAGE_SIZE,
    pixel_range="imagenet",  # â† Test manquant
    samples_per_class_per_epoch=50,
    return_labels=True
)
x, y, _ = ds_imagenet[0]
print(f"ImageNet: shape={x.shape}, min={x.min():.3f}, max={x.max():.3f}")
# VÃ©rifier que les valeurs sont dans la plage attendue aprÃ¨s normalisation ImageNet
```

## ğŸ“‹ PrioritÃ©s

1. **ğŸ”´ CRITIQUE** : Test de `no_repeat_eval=True` (aspect fondamental pour la validation)
2. **ğŸ”´ CRITIQUE** : Test des cas limites du filtrage qualitÃ© (risque de dataset trop petit)
3. **ğŸŸ¡ IMPORTANT** : Test de cohÃ©rence des indices aprÃ¨s `subsample_dataset`
4. **ğŸŸ¡ IMPORTANT** : Test de stabilitÃ© de la normalisation Vahadane
5. **ğŸŸ¡ IMPORTANT** : Test de l'Ã©quilibrage sur plusieurs Ã©poques
6. **ğŸŸ¢ BONUS** : Test du mode imagenet et robustesse

