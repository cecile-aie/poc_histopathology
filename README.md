
-----

# ğŸ”¬ Generative AI for Digital Pathology (P9 POC)

> **GÃ©nÃ©ration d'images histologiques rÃ©alistes : Comparatif GAN vs Diffusion (PixCell)**

[](https://pytorch.org/) [](https://www.docker.com/) [](https://streamlit.io/) [](https://www.google.com/search?q=LICENSE)

Ce projet est une **Preuve de Concept (POC)** visant Ã  dÃ©montrer comment l'IA gÃ©nÃ©rative peut rÃ©soudre les problÃ¨mes de raretÃ© de donnÃ©es et de biais colorimÃ©trique en histopathologie. Nous explorons et comparons deux architectures majeures pour gÃ©nÃ©rer des tissus colorectaux synthÃ©tiques : **StyleGAN2-ADA** (rapide) et **PixCell + Adapter/LoRA** (haute fidÃ©litÃ©).

-----

## ğŸ¯ Objectifs

L'histopathologie digitale souffre d'un manque de donnÃ©es annotÃ©es pour les classes rares et d'une forte variabilitÃ© technique (coloration H\&E). Ce projet vise Ã  :

1.  **GÃ©nÃ©rer des images synthÃ©tiques** biologiquement plausibles (9 classes de tissus).
2.  **Comparer deux paradigmes** : L'approche adversariale (GAN) vs l'approche par Diffusion (Foundation Models).
3.  **Valider l'utilitÃ© clinique** : Mesurer si l'ajout de ces images amÃ©liore les performances d'un classifieur de diagnostic (*Downstream Task*).

-----

## ğŸš€ Installation & DÃ©marrage (Docker)

Tout l'environnement est conteneurisÃ©. Pas besoin de gÃ©rer les versions de CUDA ou PyTorch Ã  la main \!

### PrÃ©-requis

  * Docker & Docker Compose
  * Drivers NVIDIA (pour le support GPU)

### Lancement

L'image Docker inclut **PyTorch 2.4, CUDA 12.4, Diffusers, Timm et Openslide**.

```bash
# 1. Construire et lancer le conteneur
docker-compose up --build

# 2. AccÃ©der aux services :
# ğŸ““ JupyterLab : http://localhost:8888
# ğŸˆ Streamlit  : http://localhost:8501
# ğŸ“ˆ TensorBoard: http://localhost:6006
```

-----

## ğŸ“‚ Structure du Projet

L'architecture est modulaire pour sÃ©parer la logique de gÃ©nÃ©ration, l'Ã©valuation et l'interface utilisateur.
Les dossiers de ressources et sorties (/models, /data, /outputs, /checkpoints) sont Ã  placer Ã  la racine.

```text
.
â”œâ”€â”€ p9dg/                  # ğŸ“¦ Core Package
â”‚   â””â”€â”€ histo_dataset.py   # DataGenerator avec normalisation Vahadane & Filtrage QualitÃ©
â”œâ”€â”€ metrics/               # ğŸ“ MÃ©triques gÃ©nÃ©riques
â”‚   â”œâ”€â”€ cnn_eval.py        # Eval downstream (MobileNetV2 + Calibration)
â”‚   â””â”€â”€ fid_lpips_eval.py  # Calculateur batch FID/LPIPS
â”œâ”€â”€ gan_metrics/           # ğŸ“ MÃ©triques spÃ©cifiques
â”‚   â””â”€â”€ duet_fid.py        # Calcul FID spÃ©cialisÃ© avec backbone PathoDuet
â”œâ”€â”€ scripts/               # âš™ï¸ Utilitaires Backend
â”‚   â””â”€â”€ dashboard_backend.py # Logique de l'application Streamlit
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ class_mappings.py  # Mappings classes (TUM, STR...) & couleurs
â”œâ”€â”€ notebooks/             # ğŸ““ Laboratoire d'expÃ©rimentation (dÃ©tail ci-dessous)
â”œâ”€â”€ streamlit_app.py       # ğŸˆ Application de dÃ©monstration
â”œâ”€â”€ Dockerfile             # DÃ©finition de l'environnement
â””â”€â”€ docker-compose.yml     # Orchestration des services
```
 
-----

## ğŸ““ Guide des Notebooks

Les notebooks, situÃ©s dans le dossier `notebooks/`, tracent l'histoire complÃ¨te du projet, de l'exploration des donnÃ©es Ã  la validation finale.

### ğŸ§¹ 1. PrÃ©paration & DonnÃ©es

  * **`p9_EDA.ipynb`** : Analyse Exploratoire des DonnÃ©es (distributions, inspection visuelle).
  * **`p9_PREPROCESSING.ipynb`** : Pipeline de normalisation (Vahadane) et crÃ©ation des datasets nettoyÃ©s.
  * **`01_test_datagenerator.ipynb`** : Validation technique du `HistoDataset` et du `QualityFilter`.

### ğŸ“ 2. Baselines (Les juges de paix)

  * **`02_baseline_cnn.ipynb`** : EntraÃ®nement du classifieur MobileNetV2 sur donnÃ©es rÃ©elles (RÃ©fÃ©rence).
  * **`03_baseline_radiomics.ipynb`** : Baseline non-profonde basÃ©e sur des features de texture (PyRadiomics).
  * **`04_baseline_ssm.ipynb`** : Baseline morphologique (Statistical Shape Model) pour valider la gÃ©omÃ©trie des formes.

### âš¡ 3. ModÃ©lisation GAN (StyleGAN2)

  * **`05_StyleGAN.ipynb`** : Premiers pas et tests d'entraÃ®nement inconditionnel.
  * **`06b_cGAN_IA.ipynb`** : EntraÃ®nement principal du **cGAN** (Conditionnel) avec augmentation ADA.

### ğŸ¨ 4. ModÃ©lisation Diffusion (PixCell)

  * **`07_Diffusion_model.ipynb`** : Prise en main de PixCell et du backbone UNI2-h (approche Gated).
  * **`08_LoRA_Adapter_fallback_UNET.ipynb`** : Tentative intermÃ©diaire d'adaptation simplifiÃ©e (U-Net classique).
  * **`08_UNI2h_Adapter_PixCell_LoRA.ipynb`** : **Le modÃ¨le final**. Fine-tuning hybride (Adapter + LoRA) pour une fidÃ©litÃ© maximale.

### ğŸ§ª 5. Validation & MÃ©triques

  * **`test_metrics_fid_lpips.ipynb`** : Validation unitaire des calculateurs de mÃ©triques d'image.
  * **`test_metrics_downstream.ipynb`** : Validation du pipeline d'Ã©valuation clinique (ECE, Brier Score).
  * **`02b_baseline_cnn_synth.ipynb`** : ExpÃ©rience *Downstream* finale (EntraÃ®nement sur mix RÃ©el + SynthÃ©tique).

### ğŸ” 6. Visualisation Latente

  * **`viz_embeddings_PathoDuet.ipynb`** : Projection UMAP des images via le backbone PathoDuet.
  * **`viz_embeddings_UNI.ipynb`** : Exploration des gÃ©odÃ©siques et interpolations dans l'espace UNI2-h.

-----

## ğŸ› ï¸ Stack Technique

  * **Core :** Python 3.10, PyTorch 2.4, CUDA 12.4
  * **GenAI :** `diffusers` (HuggingFace), `timm` (Vision Transformers), StyleGAN2-ADA (PyTorch impl.)
  * **Medical :** `openslide-python`, `torch-staintools` (Normalisation)
  * **Ops :** Docker, Nvidia Container Toolkit

-----

## ğŸ“š Documentation

| ModÃ¨le | Description |
|--------|-------------|
| [ğŸŸ£ cGAN](docs/cGAN_README.md) | ModÃ¨le StyleGAN2 + tÃªte PathoDuet |
| [ğŸ”µ PixCell (Diffusion)](docs/pixcell_README.md) | Pipeline diffusion UNI2-h |
| [ğŸŸ¢ Radiomics](docs/baseline_radiomics_README.md) | Extraction PyRadiomics |
| [ğŸŸ  SSM](docs/baseline_ssm_README.md) | ModÃ¨les de forme statistiques |
| [âš« CNN Baseline](docs/baseline_CNN.md) | MobileNetV2 classifier |


-----

## ğŸ“ Auteurs & CrÃ©dits

Ce projet s'appuie sur de nombreux travaux de recherche, notamment :

  * **NCT-CRC-HE-100K** (Kather et al.) pour le dataset.
  * **PixCell** & **UNI** (Mahmood Lab et al.) pour les Foundation Models en pathologie.
  * **Pathoduet** (Shengyi Hua & al.) pour le backbone spÃ©cialisÃ© en histopathologie (utilisÃ© pour FID-Duet et tÃªte de sortie du discriminateur cGAN)

*Projet rÃ©alisÃ© dans le cadre du parcours IngÃ©nieur IA OpenClassRooms (p9-DÃ©veloppez une preuve de concept).*
